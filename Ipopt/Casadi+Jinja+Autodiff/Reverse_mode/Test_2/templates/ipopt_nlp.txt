// In this file I will try to use the CasADi created file to evaluate functions 

#include "{{project_name}}_nlp.hpp"

#include <cassert>
#include <iostream>

#include <autodiff/reverse/var.hpp>
using namespace autodiff;


var f(var* x)
{
  return {{objective1}};
}

{% for i in range(m) %}
var g_{{i}}(var* x)
{
  return {{constrains1[i]}};
}
{% endfor %}





using namespace Ipopt;

// constructor
HS071_NLP::HS071_NLP()
{}

//destructor
HS071_NLP::~HS071_NLP()
{}

// returns the size of the problem
bool HS071_NLP::get_nlp_info(Index& n, Index& m, Index& nnz_jac_g,
                             Index& nnz_h_lag, IndexStyleEnum& index_style)
{

  
  // The problem described in HS071_NLP.hpp has 4 variables, x[0] through x[3]
  n = {{n}};

  // one equality constraint and one inequality constraint
  m = {{m}};

  // in this example the jacobian is dense and contains 8 nonzeros
  nnz_jac_g = {{j_g_nze}};

  // the hessian is also dense and has 16 total nonzeros, but we
  // only need the lower left corner (since it is symmetric)
  nnz_h_lag = {{h_f_nze}};

  // use the C style indexing (0-based)
  index_style = TNLP::C_STYLE;

  return true;
}

// returns the variable bounds
bool HS071_NLP::get_bounds_info(Index n, Number* x_l, Number* x_u,
                                Index m, Number* g_l, Number* g_u)
{
  // here, the n and m we gave IPOPT in get_nlp_info are passed back to us.
  // If desired, we could assert to make sure they are what we think they are.
  assert(n == {{n}});
  assert(m == {{m}});


  {% for i in range(n) %}
    x_l[{{i}}] = {{x_l[i]}};
    x_u[{{i}}] = {{x_u[i]}};
  {% endfor %}

  // the variables have upper bounds of 5
  {% for i in range(m) %}
    g_l[{{i}}] = {{g_l[i]}};
    g_u[{{i}}] = {{g_u[i]}};
  {% endfor %}

  return true;
}

// returns the initial point for the problem
bool HS071_NLP::get_starting_point(Index n, bool init_x, Number* x,
                                   bool init_z, Number* z_L, Number* z_U,
                                   Index m, bool init_lambda,
                                   Number* lambda)
{
  // Here, we assume we only have starting values for x, if you code
  // your own NLP, you can provide starting values for the dual variables
  // if you wish
  assert(init_x == true);
  assert(init_z == false);
  assert(init_lambda == false);

  {% for i in range(n) %}
    x[{{i}}] = {{x_start[i]}};
  {% endfor %}

  return true;
}

// returns the value of the objective function
bool HS071_NLP::eval_f(Index n, const Number* x, bool new_x, Number& obj_value)
{
  assert(n == {{n}});

  var* p = (var*) calloc(n, sizeof(var));
  for(int i = 0; i < n; i++) {
    p[i] = x[i];
  }
  obj_value = Number(f(p));


  return true;
}

// return the gradient of the objective function grad_{x} f(x)
bool HS071_NLP::eval_grad_f(Index n, const Number* x, bool new_x, Number* grad_f)
{
  assert(n == {{n}});

  // Gradiente restituito come vettore colonna

  var* p = (var*) calloc(n, sizeof(var));
  for(int i = 0; i < n; i++) {
    p[i] = x[i];
  }

  auto d_f = derivativesx(f(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));

  for (int i = 0; i < n; i++) {
    grad_f[i] = Number(d_f[i]);
  }


  return true;
}

// return the value of the constraints: g(x)
bool HS071_NLP::eval_g(Index n, const Number* x, bool new_x, Index m, Number* g)
{
  assert(n == {{n}});
  assert(m == {{m}});


  var* p = (var*) calloc(n, sizeof(var));
  for(int i = 0; i < n; i++) {
    p[i] = x[i];
  }

  {% for i in range(m) %}
  g[{{i}}] = Number(g_{{i}}(p));
  {% endfor %}

  return true;
}

// return the structure or values of the jacobian
bool HS071_NLP::eval_jac_g(Index n, const Number* x, bool new_x,
                           Index m, Index nele_jac, Index* iRow, Index *jCol,
                           Number* values)
{
  if (values == NULL) {
    // return the structure of the jacobian

    var* p = (var*) calloc(n, sizeof(var));
    for(int i = 0; i < n; i++) {
      p[i] = rand() % 10000 + 1;
    }

    {% for i in range(m) %}
    auto d_g_{{i}} = derivativesx(g_{{i}}(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% endfor %}

    int index = 0;
    {% for i in range(m) %}
    for(int i = 0; i < n; i++) {
      if (d_g_{{i}}[i] != 0) {
        iRow[index] = {{i}};
        jCol[index] = i;
        index++;
      }
    }
    {% endfor %}


  }
  else {
    // return the values of the jacobian of the constraints

    var* p = (var*) calloc(n, sizeof(var));
    for(int i = 0; i < n; i++) {
      p[i] = x[i];
    }

    {% for i in range(m) %}
    auto d_g_{{i}} = derivativesx(g_{{i}}(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% endfor %}

    int index = 0;
    {% for i in range(m) %}
    for(int i = 0; i < n; i++) {
      if(Number(d_g_{{i}}[i]) != 0) {
        values[index] = Number(d_g_{{i}}[i]);
        index++;
      }
    }
    {% endfor %}
  }

  return true;
}

//return the structure or values of the hessian
bool HS071_NLP::eval_h(Index n, const Number* x, bool new_x,
                       Number obj_factor, Index m, const Number* lambda,
                       bool new_lambda, Index nele_hess, Index* iRow,
                       Index* jCol, Number* values)
{
  if (values == NULL) {
   
    var* p = (var*) calloc(n, sizeof(var));
    for(int i = 0; i < n; i++) {
      p[i] = rand() % 10000 + 1;
    }

    double* values1 = (double*) calloc(n*n,sizeof(double));

    auto d_f = derivativesx(f(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));

    {% for i in range(n) %}
    auto dd_f{{i}} = derivativesx(d_f[{{i}}], wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% endfor %}

    {% set ind = namespace(n=0) %}
    {% for i in range(n) %}
    {% for j in range(i+1) %}
    values1[{{ind.n}}] = Number(dd_f{{i}}[{{j}}]);{% set ind.n = ind.n + 1 %}{% endfor %}{% endfor %}

    {% for i in range(m) %}
    auto d_g_{{i}} = derivativesx(g_{{i}}(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% for j in range(n) %}
    auto dd_g_{{i}}{{j}} = derivativesx(d_g_{{i}}[{{j}}], wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));{% endfor %}
    {% set ind = namespace(n=0) %}{% for l in range(n) %}
    {% for k in range(l+1) %}
    values1[{{ind.n}}] += Number(dd_g_{{i}}{{l}}[{{k}}]);{% set ind.n = ind.n + 1 %}{% endfor %}{% endfor %}


    {% endfor %}


    int idx = 0;
    for (int i = 0; i < n*n; i++) {
      if (values1[i] != 0) {
        int line_index = 0;
        int k = i;
        while (k > line_index) {
          k -= (line_index + 1);
          line_index++;
        }
        iRow[idx] = line_index;
        jCol[idx] = k;
        idx++;
      }
    }  

    assert(idx == nele_hess); // nele_hess == 10
  }
  else {
    // return the values. This is a symmetric matrix, fill the lower left
    // triangle only


    var* p = (var*) calloc(n, sizeof(var));
    for(int i = 0; i < n; i++) {
      p[i] = x[i];
    }

    double* values1 = (double*) calloc(n*n,sizeof(double));

    auto d_f = derivativesx(f(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));

    {% for i in range(n) %}
    auto dd_f{{i}} = derivativesx(d_f[{{i}}], wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% endfor %}

    {% set ind = namespace(n=0) %}
    {% for i in range(n) %}
    {% for j in range(i+1) %}
    values1[{{ind.n}}] = Number(dd_f{{i}}[{{j}}]) * obj_factor;{% set ind.n = ind.n + 1 %}{% endfor %}{% endfor %}

    {% for i in range(m) %}
    auto d_g_{{i}} = derivativesx(g_{{i}}(p), wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));
    {% for j in range(n) %}
    auto dd_g_{{i}}{{j}} = derivativesx(d_g_{{i}}[{{j}}], wrt(p[0],{% for i in range(1,n-1) %} p[{{i}}],{% endfor %} p[{{n-1}}]));{% endfor %}
    {% set ind = namespace(n=0) %}{% for l in range(n) %}
    {% for k in range(l+1) %}
    values1[{{ind.n}}] += Number(dd_g_{{i}}{{l}}[{{k}}]) * lambda[{{i}}];{% set ind.n = ind.n + 1 %}{% endfor %}{% endfor %}


    {% endfor %}


    int index = 0;
    for(int i = 0; i < n*n; i++) {
      if(values1[i] != 0) {
        values[index] = values1[i];
        index++;
      }
    }




  }

  return true;
}

void HS071_NLP::finalize_solution(SolverReturn status,
                                  Index n, const Number* x, const Number* z_L, const Number* z_U,
                                  Index m, const Number* g, const Number* lambda,
                                  Number obj_value,
				  const IpoptData* ip_data,
				  IpoptCalculatedQuantities* ip_cq)
{
  // here is where we would store the solution to variables, or write to a file, etc
  // so we could use the solution.

  // For this example, we write the solution to the console
  std::cout << std::endl << std::endl << "Solution of the primal variables, x" << std::endl;
  for (Index i=0; i<n; i++) {
     std::cout << "x[" << i << "] = " << x[i] << std::endl;
  }

  std::cout << std::endl << std::endl << "Solution of the bound multipliers, z_L and z_U" << std::endl;
  for (Index i=0; i<n; i++) {
    std::cout << "z_L[" << i << "] = " << z_L[i] << std::endl;
  }
  for (Index i=0; i<n; i++) {
    std::cout << "z_U[" << i << "] = " << z_U[i] << std::endl;
  }

  std::cout << std::endl << std::endl << "Objective value" << std::endl;
  std::cout << "f(x*) = " << obj_value << std::endl;

  std::cout << std::endl << "Final value of the constraints:" << std::endl;
  for (Index i=0; i<m ;i++) {
    std::cout << "g(" << i << ") = " << g[i] << std::endl;
  }
}
